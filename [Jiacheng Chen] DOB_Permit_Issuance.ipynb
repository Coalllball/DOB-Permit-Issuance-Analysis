{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOB Permit Issuance Analysis\n",
    "\n",
    "*Author: Jiacheng Chen*\n",
    "\n",
    "*Date: Aug 23, 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "installed_packages = [pkg.key for pkg in pkg_resources.working_set]\n",
    "print(installed_packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Raw Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw issuance dataset\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "# Identify Opendata NYC Source Domain\n",
    "client = Socrata(\"data.cityofnewyork.us\",\"8rVKWjYb75ZgPpouoX7bmtWNL\")\n",
    "\n",
    "# Get Active Major Construction permits through SoQL query\n",
    "\n",
    "results = client.get_all(\"ipu4-2q9a\", where=\"job_type = 'NB' OR job_type = 'A1'\") # 'results' is a json \n",
    "# Convert to pandas DataFrame\n",
    "results_df = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.to_csv('MajorConstructionDF.csv') # I exported the df to csv for eaiser reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">SoQL doesn't support the SUBSTR operator and the dates of the raw data come in as strings. What a pity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter `Current Active` Constructions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'dates' in raw df to date type\n",
    "from datetime import datetime\n",
    "results_df['expiration_date'] = pd.to_datetime(results_df['expiration_date'], format='mixed', dayfirst=True,  errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Current Date\n",
    "today = datetime.now()\n",
    "\n",
    "# Get currently active constructions\n",
    "activeConstruction_df = results_df[results_df['expiration_date'] >= today]\n",
    "\n",
    "# Format all date columns\n",
    "# extract date columns from the raw df\n",
    "dateToChange = results_df.columns[results_df.columns.str.contains('date')].tolist() \n",
    "\n",
    "# Convert 'dates' in raw df to date type\n",
    "activeConstruction_df[dateToChange] = activeConstruction_df[dateToChange].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "activeConstruction_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "**Key Metrics Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the categorical variables that don't have significant amount of missing values to be key metrics, such as `job_type`, `permit_type`, `recidential`, `owner's business type`, `non profit`, and I also included `dates` in the table, along with `GIS` variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key columns\n",
    "activeConstruction_df_summary = activeConstruction_df[['borough','bin__', 'job__', 'job_type', \n",
    "                                                       'bldg_type', 'residential','self_cert',\n",
    "                                                       'permit_type','permit_subtype','permittee_s_license_type',\n",
    "                                                       'permit_status', 'filing_status', 'owner_s_business_type',\n",
    "                                                       'permit_si_no',\n",
    "                                                       'filing_date', 'issuance_date', 'expiration_date',\n",
    "                                                       'job_start_date','non_profit','gis_latitude', \n",
    "                                                       'gis_longitude','gis_council_district']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and remove duplicates entries that ate exact identical\n",
    "activeConstruction_df_cleaned = activeConstruction_df_summary[~activeConstruction_df_summary.duplicated(keep='last')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed there are some entries that a job number matchs mutiple permits and ves versa, but they have different work types or permit types. Considering the complexity of construction works, I decided only remove the rows that are exactly identical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Job Types and Boroughs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Borough and Job types, count the number of each job type. \n",
    "jobType_sumTable = pd.DataFrame(activeConstruction_df_cleaned.groupby(['borough', 'job_type'])['job__'].count()).reset_index()\n",
    "jobType_sumTable.columns = ('Borough', 'Job Type', 'Count') # rename columns\n",
    "\n",
    "# Visualize the Borough Jobtype table\n",
    "import seaborn as sns\n",
    "sns.catplot(data=jobType_sumTable, x='Borough', y='Count', hue='Job Type', kind=\"bar\", legend=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Number of Jobs\")\n",
    "plt.title(\"Job Types by Borough\")\n",
    "plt.legend()  # Show the legend\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"job_types_by_borough.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table, transform Job Type to columns\n",
    "jobType_sumTable = jobType_sumTable.pivot(index='Borough', columns='Job Type', values='Count').reset_index()\n",
    "jobType_sumTable.columns = ['Borough', 'Job Type A1', 'Job Type NB'] # rename columns\n",
    "\n",
    "# Calculate row and column total Jobs by Boroughs and by Job Types\n",
    "jobType_sumTable['Total'] = jobType_sumTable['Job Type A1'] + jobType_sumTable['Job Type NB'] # row total\n",
    "total_row = jobType_sumTable[[\"Job Type A1\", \"Job Type NB\", \"Total\"]].sum() # column total\n",
    "total_row['Borough'] = 'Total'\n",
    "jobType_sumTable = pd.concat([jobType_sumTable, pd.DataFrame([total_row])], ignore_index=True) # append column total to the table\n",
    "\n",
    "# Save the Borough_JobType table to excel\n",
    "import openpyxl\n",
    "jobType_sumTable.to_excel(\"job_types_by_borough.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobType_sumTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Permit Types and Boroughs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Borough and Job types, count the number of each job type. \n",
    "permitType_sumTable = pd.DataFrame(activeConstruction_df_cleaned.groupby(['borough', 'permit_type'])['job__'].count()).reset_index()\n",
    "permitType_sumTable.columns = ('Borough', 'Permit Type', 'Count')\n",
    "\n",
    "# Visualize the Permit Jobtype table\n",
    "import seaborn as sns\n",
    "sns.catplot(data=permitType_sumTable, x='Borough', y='Count', hue='Permit Type', kind=\"bar\", legend=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Borough\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Number of Permit\")\n",
    "plt.title(\"Permit Types by Borough\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"permit_types_by_borough.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table, transform Permit Type to columns\n",
    "permitType_sumTable = permitType_sumTable.pivot(index='Borough', columns='Permit Type', values='Count').reset_index()\n",
    "\n",
    "#replace missing value to 0\n",
    "permitType_sumTable.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate row and column total Jobs by Boroughs and by Permit Types\n",
    "permitType_sumTable['Total'] = permitType_sumTable.iloc[:, 1:].sum(axis=1)# row total\n",
    "total_row = permitType_sumTable.iloc[:, 1:].sum() # column total\n",
    "total_row['Borough'] = 'Total'\n",
    "permitType_sumTable = pd.concat([permitType_sumTable, pd.DataFrame([total_row])], ignore_index=True) # append column total to table\n",
    "\n",
    "# Save the Borough_JobType table to excel\n",
    "permitType_sumTable.to_excel(\"permit_types_by_borough.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permitType_sumTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When the currently active major construction permits issued**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers of Permit Issuance per day in each borough\n",
    "TS_issuDate_Boro = activeConstruction_df_cleaned[['borough', 'issuance_date','job__']]\n",
    "TS_issuDate_Boro = TS_issuDate_Boro.groupby(['borough','issuance_date'])['job__'].count().reset_index(name='issuance_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Plot\n",
    "import matplotlib.pyplot as plt # I used matplotlin here cuz it's eaiser to resample the df by different time windows\n",
    "\n",
    "TS_issuDate_Boro.index = TS_issuDate_Boro['issuance_date']\n",
    "unique_boroughs = TS_issuDate_Boro['borough'].unique()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Loop through each borough to plot its time series data\n",
    "for borough in unique_boroughs:\n",
    "    data = TS_issuDate_Boro[TS_issuDate_Boro['borough'] == borough]['issuance_count']\n",
    "    data_months = data.resample('M').sum() # Resample to get monthly data\n",
    "    plt.plot(data_months, label=borough)\n",
    "\n",
    "# Plot Settings\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Issuances')\n",
    "plt.title('Current Active Major Constructions \\n Permit Issuances Amount by Borough (Monthly)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(pd.Timestamp('2022-01-01'), datetime.now())\n",
    "plt.xticks(rotation=45) \n",
    "plt.savefig('TS_issuanceAmount_boro_monthly.png', dpi = 300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most currently active major construction permits were issued within **one year**, with some work begun as early as **January 1, 2022**. \n",
    "\n",
    "**Brooklyn** has the highest number of major ongoing construction projects. Notably, the issuance permits in Brooklyn has a peak in January 2023.\n",
    "\n",
    "There are a few **outliers** that have been under construction since 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra long constructions \n",
    "# outliars\n",
    "activeConstruction_df_cleaned[activeConstruction_df_cleaned['issuance_date']<'2022-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(pxtest, x='issuance_date', y='count',color='borough')\n",
    "fig.update_xaxes(ticks= \"outside\",\n",
    "                 ticklabelmode= \"period\", \n",
    "                 tickcolor= \"black\", \n",
    "                 ticklen=10, \n",
    "                 minor=dict(\n",
    "                     ticklen=4,  \n",
    "                     dtick=7*24*60*60*1000,  \n",
    "                     tick0=\"2016-07-03\", \n",
    "                     griddash='dot', \n",
    "                     gridcolor='white'),\n",
    "                 rangeslider_visible=True,\n",
    "                 rangeselector=dict(\n",
    "                     buttons=list([\n",
    "                         dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                         dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                         dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
    "                         dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
    "                         dict(step=\"all\")])\n",
    "                     )\n",
    "                )\n",
    "fig.show()\n",
    "\n",
    "# Code based on the example from Plotly at https://plotly.com/python/time-series/#adding-minor-ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an interactive line plot that provides a comprehensive view of when the permits of active major constructions issued. This includes projects that were issued permits before January 1, 2022. Data points after today indicate projects that are currently undergoing the permit issuance process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Active major constrction sites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Convert the working df to gdf\n",
    "activeConstruction_gdf = gpd.GeoDataFrame(activeConstruction_df_cleaned, \n",
    "                                          geometry=gpd.points_from_xy(activeConstruction_df_cleaned.gis_longitude, activeConstruction_df_cleaned.gis_latitude))\n",
    "# Set crs to 4326\n",
    "activeConstruction_gdf.crs = 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the points\n",
    "activeConstruction_gdf.plot(alpha=0.1, markersize=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spatial Join with Business Improvement Districts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BetaNYC has a very practical project that showcases various administrative boundaries in NYC. I found it would be interesting to explore Business Improvement Districts in context with major construction projects.\n",
    "\n",
    "BetaNYC NYC Boundaries Map: https://beta.nyc/products/boundaries-map/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in BID geojson\n",
    "bid_url = \"https://data.cityofnewyork.us/resource/7jdm-inj8.geojson\"\n",
    "bid_gdf = gpd.read_file(bid_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bid and active construction layers to map \n",
    "fig, bid_ac_ax= plt.subplots(figsize=(12,12))\n",
    "\n",
    "# layer settings\n",
    "bid_gdf.plot(alpha = 0.7, edgecolor = 'gray', color = 'green', ax=bid_ac_ax)\n",
    "activeConstruction_gdf.plot(alpha = 0.5, markersize = 1, ax=bid_ac_ax)\n",
    "\n",
    "# add a basemap\n",
    "basemap = cx.providers.CartoDB.Positron\n",
    "cx.add_basemap(bid_ac_ax, crs = 4326, source=basemap)\n",
    "\n",
    "bid_ac_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bid_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial Join bid polygon geom to the point dataset\n",
    "joined_layer_bid_ac = gpd.sjoin(activeConstruction_gdf, bid_gdf[['bid', 'geometry']], how=\"right\", predicate='within')\n",
    "\n",
    "# Group by and count number of points in bid polygons\n",
    "joined_layer_bid_ac_count = gpd.GeoDataFrame(joined_layer_bid_ac.groupby(['bid','geometry']).size().reset_index(name = 'Count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the amount of active major constructions by bid\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "# layer setting\n",
    "joined_bid_ac_ax = joined_layer_bid_ac_count.plot(column='Count', legend=True)\n",
    "\n",
    "# add basemap\n",
    "cx.add_basemap(joined_bid_ac_ax, crs = 4326, source=basemap)\n",
    "\n",
    "# title and other settings\n",
    "plt.title('Current Acvtive Major Constructions Count \\n Business Improvement Districts ')\n",
    "joined_bid_ac_ax.axis('off')\n",
    "\n",
    "# save the output\n",
    "plt.savefig('bid_activeMajorCons_map.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive map to navigate better\n",
    "joined_layer_bid_ac_count.explore(column='Count', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Business Improvement Districts that have more than 20 active major constructions. \n",
    "joined_layer_bid_ac_count[joined_layer_bid_ac_count['Count']>=20].sort_values(by='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of New York City's business improvement districts, lower and midtown Manhattan are very busy with construction. Downtown Brooklyn has some as well. And I'm happy to see more constructions in LIC and Flushing because that suggests community vibrancy and business development. The increase in construction activity indicates positive growth and opportunity in these areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the gdf to excel\n",
    "joined_layer_bid_ac.to_excel('Bid_ActiveMajorContruction.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date variables to string before exporting to shp file\n",
    "\n",
    "# save date columns to a list\n",
    "dateToStr = joined_layer_bid_ac.columns[joined_layer_bid_ac.columns.str.contains('date')].tolist() \n",
    "# for each column, convert datetime to date string\n",
    "for column in dateToStr:\n",
    "    joined_layer_bid_ac[column] = joined_layer_bid_ac[column].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export layer to shp \n",
    "joined_layer_bid_ac.to_file('bid_ActiveMajorConstruction.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to conduct a Spatial Aitocorrelation analysis to determine whether clusters of active construction projects exist. My goal is to identify where the clusters are and to compare them with the Business Improvement Districts map. To achieve this, I employed Moran's Index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the basemap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shapely\n",
    "\n",
    "def make_grid(gdf, n_cells):\n",
    "    gdf = gdf.copy()\n",
    "    xmin, ymin, xmax, ymax= gdf.total_bounds\n",
    "    cell_size = (xmax-xmin)/n_cells\n",
    "    # create the cells in a loop\n",
    "    grid_cells = []\n",
    "    for x0 in np.arange(xmin, xmax+cell_size, cell_size ):\n",
    "        for y0 in np.arange(ymin, ymax+cell_size, cell_size):\n",
    "            x1 = x0-cell_size\n",
    "            y1 = y0+cell_size\n",
    "            grid_cells.append( shapely.geometry.box(x0, y0, x1, y1)  )\n",
    "    grid = gpd.GeoDataFrame(grid_cells, columns=['geometry'], crs=gdf.crs)\n",
    "    return grid\n",
    "\n",
    "# code based on lecture note from WIll Geary at https://github.com/willgeary/info615/blob/main/modules/09-spatial-point-patterns/notebook.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genarate a grid over map\n",
    "grid = make_grid(activeConstruction_gdf, n_cells=80)\n",
    "\n",
    "# overlap the points with grid\n",
    "ax = activeConstruction_gdf.plot(markersize=2)\n",
    "grid.plot(ax=ax, facecolor='none', edgecolor='grey', linewidth=1)\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to aggregate and summarize points over grid\n",
    "def rasterize(gdf, grid, aggfunc=\"count\", column=None, plot=True):\n",
    "    merged = gpd.sjoin(gdf, grid, how='left', predicate='within').copy()\n",
    "    if aggfunc == \"count\":\n",
    "        column = 'count'\n",
    "        output_col = column\n",
    "        merged[column] = 1\n",
    "    else:\n",
    "        output_col = column + \"_\" + aggfunc   \n",
    "    dissolved = merged.dissolve(by=\"index_right\", aggfunc=aggfunc)[[column]]\n",
    "    dissolved.columns = [output_col]\n",
    "    grid.loc[dissolved.index, output_col] = dissolved[output_col].values\n",
    "    if plot:\n",
    "        ax = grid.plot(column=output_col, figsize=(12, 8), edgecolor=\"grey\", legend=True)\n",
    "        ax.axis('off')\n",
    "        cx.add_basemap(ax,source=cx.providers.CartoDB.Positron,crs=gdf.crs)\n",
    "        plt.show()\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rasterize(activeConstruction_gdf, grid, aggfunc=\"count\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop grid cells contain no points\n",
    "r = r.dropna(subset=['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Global Moran's I**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a spatial weights matrix\n",
    "from pysal.lib import weights\n",
    "\n",
    "# Use Queen contiguity to generate weights\n",
    "w = weights.Queen.from_dataframe(r)\n",
    "# row-standardized weight matrix\n",
    "w.transform = 'R'\n",
    "\n",
    "w.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global spatial autocorrelation hypothesis test\n",
    "from pysal.explore import esda\n",
    "\n",
    "# H0: There is no spatial autocorrelation \n",
    "# Ha: There no spatial autocorrelation \n",
    "moran = esda.moran.Moran(r['count'], w, permutations=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated p-value is very low. We are confident to reject the null hypothesis and conclude that spatial autocorrelation is in fact present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the Global Moran's I results\n",
    "from splot.esda import plot_moran\n",
    "plot_moran(moran)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Moran's I**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for local spatial autocorrelation\n",
    "local_moran = esda.moran.Moran_Local(r['count'], w) # use the same wright matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot local moran's I results\n",
    "from splot.esda import plot_local_autocorrelation\n",
    "plot_local_autocorrelation(local_moran, r, 'count', p=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare with Business Improvement Districts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['local_moran_Is'] = local_moran.Is\n",
    "r['local_moran_p_value'] = local_moran.p_sim\n",
    "r['local_moran_quadrant'] = local_moran.q\n",
    "\n",
    "alpha = 0.05\n",
    "hotspots = r.query(f\"local_moran_p_value < {alpha} & local_moran_quadrant == 1\")\n",
    "coldspots = r.query(f\"local_moran_p_value < {alpha} & local_moran_quadrant == 3\")\n",
    "doughnuts = r.query(f\"local_moran_p_value < {alpha} & local_moran_quadrant == 2\")\n",
    "diamonds = r.query(f\"local_moran_p_value < {alpha} & local_moran_quadrant == 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, cluster_map = plt.subplots(figsize = (16,8))\n",
    "r.plot(ax=cluster_map, facecolor='none', alpha=0.05)\n",
    "hotspots.plot(color='red', ax=cluster_map, label='Hot Spot')\n",
    "coldspots.plot(color='blue', ax=cluster_map, label='Cold Spot')\n",
    "doughnuts.plot(color='blue', ax=cluster_map, label='Doughnuts', alpha=0.5, edgecolor='blue')\n",
    "diamonds.plot(color='red', ax=cluster_map, label='Diamonds',alpha=0.5, edgecolor='red')\n",
    "\n",
    "joined_layer_bid_ac_count.plot(column='Count', legend=True, ax=cluster_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tessellation grids appear to be too large compare to the bid boundries. However, we can generally tell there are overlaps between the hot spots and the business improvement districts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
